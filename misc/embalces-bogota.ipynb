{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Tag\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import requests\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the array with the starting date\n",
    "from_date = datetime.datetime(2024, 5, 1)\n",
    "dates = [from_date]\n",
    "\n",
    "# Add one month at a time until we reach today\n",
    "while dates[-1] < datetime.datetime.today():\n",
    "    dates.append(dates[-1] + relativedelta(months=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [01:51<00:00,  1.53s/it]\n",
      "100%|██████████| 68/68 [01:03<00:00,  1.07it/s]\n",
      "100%|██████████| 66/66 [01:03<00:00,  1.03it/s]\n",
      "100%|██████████| 73/73 [01:07<00:00,  1.08it/s]\n",
      "100%|██████████| 85/85 [01:19<00:00,  1.06it/s]\n",
      "100%|██████████| 89/89 [01:29<00:00,  1.01s/it]\n",
      "100%|██████████| 92/92 [01:29<00:00,  1.03it/s]\n",
      "100%|██████████| 93/93 [01:27<00:00,  1.06it/s]\n",
      "100%|██████████| 80/80 [01:15<00:00,  1.05it/s]\n",
      "100%|██████████| 75/75 [01:13<00:00,  1.02it/s]\n",
      "100%|██████████| 31/31 [00:30<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "found_articles: list[Tag] = []\n",
    "\n",
    "def met_condition(anchor) -> bool:\n",
    "    lower = anchor.get_text().lower()\n",
    "    return 'consumo' in lower and 'agua' in lower\n",
    "\n",
    "\n",
    "for date in dates:\n",
    "    base_page = f\"https://bogota.gov.co/archivo/{date.strftime('%Y%m')}?tipo=article\"\n",
    "    html_doc = requests.get(base_page).content\n",
    "    soup = BeautifulSoup(html_doc)\n",
    "    anchors = soup.find_all(\"a\", recursive=True)\n",
    "\n",
    "    last_page_anchor = next((a for a in anchors if 'ltima' in a.get('title', '').lower()), None)\n",
    "\n",
    "    if not last_page_anchor: break\n",
    "\n",
    "    last_page = int(last_page_anchor.get('href').split('=')[-1])\n",
    "\n",
    "    for i in tqdm(range(0, last_page)):\n",
    "        url = f'{base_page}&page={i}'\n",
    "        r = html_doc if html_doc and i == 0 else requests.get(url).content\n",
    "        soup = BeautifulSoup(r)\n",
    "        anchors = soup.find_all(\"a\", recursive=True)\n",
    "\n",
    "        filtered_anchors = [a for a in anchors if met_condition(a)]\n",
    "        found_articles += filtered_anchors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [f'https://bogota.gov.co/{a.get(\"href\")}' for a in found_articles]\n",
    "df_urls = pd.DataFrame(urls, columns=['URL'])\n",
    "df_urls.to_csv('../data/embalces_urls.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
